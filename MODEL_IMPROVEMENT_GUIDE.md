# üöÄ How to Make Your Model Better

Complete guide to improving Plasmodium detection accuracy and performance.

---

## üìä Current Performance Assessment

### Step 1: Check Your Current Metrics

```bash
python src/eval.py --weights runs/plasmodium_yolov8/weights/best.pt --data config/data_datasetninja.yaml
```

**Key Metrics to Note:**
- mAP50-95: _____
- mAP50: _____
- Precision: _____
- Recall: _____
- Per-class performance: _____

### Performance Targets

| Metric | Current | Good | Excellent |
|--------|---------|------|-----------|
| mAP50-95 | ? | > 0.7 | > 0.85 |
| mAP50 | ? | > 0.85 | > 0.95 |
| Precision | ? | > 0.8 | > 0.9 |
| Recall | ? | > 0.8 | > 0.9 |

---

## üéØ Improvement Strategies (Ranked by Impact)

### Strategy 1: More Training Data (Highest Impact) ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê

**Why:** More diverse data = better generalization

**How to Get More Data:**

1. **Collect More Images**
   - Different microscopes
   - Different lighting conditions
   - Different blood smear preparations
   - Different parasite densities

2. **Use Data Augmentation** (See Strategy 4)

3. **Combine Multiple Datasets**
   ```python
   # In convert script, merge multiple sources
   dataset1/ + dataset2/ + dataset3/ = combined_dataset/
   ```

**Expected Improvement:** +5-15% mAP

---

### Strategy 2: Train Longer ‚≠ê‚≠ê‚≠ê‚≠ê

**Current:** Probably 100 epochs

**Try:**
```bash
# Train for 200-300 epochs
python src/train.py \
  --data config/data_datasetninja.yaml \
  --epochs 200 \
  --batch 16 \
  --device cuda:0 \
  --patience 100
```

**Monitor for:**
- Training keeps improving ‚Üí continue
- Validation stops improving ‚Üí overfitting, stop earlier

**Expected Improvement:** +2-8% mAP

---

### Strategy 3: Use a Larger Model ‚≠ê‚≠ê‚≠ê‚≠ê

**Current:** YOLOv8n (nano) - 3M parameters

**Upgrade Options:**

```bash
# Small model (11M parameters)
python src/train.py \
  --model yolov8s.pt \
  --data config/data_datasetninja.yaml \
  --epochs 150 \
  --batch 16

# Medium model (26M parameters) - Best balance
python src/train.py \
  --model yolov8m.pt \
  --data config/data_datasetninja.yaml \
  --epochs 150 \
  --batch 8

# Large model (44M parameters)
python src/train.py \
  --model yolov8l.pt \
  --data config/data_datasetninja.yaml \
  --epochs 150 \
  --batch 4
```

**Tradeoff:**
- ‚úÖ Better accuracy (+5-10% mAP)
- ‚ùå Slower inference
- ‚ùå Needs more GPU memory

**Expected Improvement:** +5-12% mAP

---

### Strategy 4: Advanced Data Augmentation ‚≠ê‚≠ê‚≠ê‚≠ê

**Create Custom Hyperparameters:**

Create `config/hyp_advanced.yaml`:

```yaml
# Learning rates
lr0: 0.01
lrf: 0.01

# Augmentation
degrees: 15.0          # Rotation
translate: 0.1         # Translation
scale: 0.5             # Scaling
shear: 2.0             # Shear
perspective: 0.0001    # Perspective
flipud: 0.5            # Flip up-down
fliplr: 0.5            # Flip left-right
mosaic: 1.0            # Mosaic augmentation
mixup: 0.1             # Mixup augmentation

# Color augmentation
hsv_h: 0.015           # Hue
hsv_s: 0.7             # Saturation
hsv_v: 0.4             # Value/brightness

# Other
copy_paste: 0.1        # Copy-paste augmentation
```

**Train with it:**
```bash
python src/train.py \
  --data config/data_datasetninja.yaml \
  --cfg config/hyp_advanced.yaml \
  --epochs 150
```

**Expected Improvement:** +3-8% mAP

---

### Strategy 5: Optimize Image Size ‚≠ê‚≠ê‚≠ê

**Current:** Default 640x640

**Experiment:**

```bash
# Higher resolution (better for small objects)
python src/train.py \
  --data config/data_datasetninja.yaml \
  --imgsz 1280 \
  --batch 4 \
  --epochs 150

# Or try 800x800
python src/train.py \
  --data config/data_datasetninja.yaml \
  --imgsz 800 \
  --batch 8 \
  --epochs 150
```

**Guidelines:**
- Small parasites ‚Üí higher resolution
- Large parasites ‚Üí 640 is fine
- More GPU memory needed for larger sizes

**Expected Improvement:** +2-6% mAP

---

### Strategy 6: Balance Your Dataset ‚≠ê‚≠ê‚≠ê

**Check Class Distribution:**

```python
import os
from pathlib import Path

# Count classes in labels
class_counts = {0: 0, 1: 0, 2: 0, 3: 0}

label_dir = Path("Dataset_DatasetNinja/labels/train")
for label_file in label_dir.glob("*.txt"):
    with open(label_file) as f:
        for line in f:
            class_id = int(line.split()[0])
            class_counts[class_id] += 1

print("Class distribution:")
print(f"Falciparum: {class_counts[0]}")
print(f"Vivax: {class_counts[1]}")
print(f"Ovale: {class_counts[2]}")
print(f"Malariae: {class_counts[3]}")
```

**If Imbalanced:**

Option A: Collect more data for underrepresented classes

Option B: Use class weights (modify training script):

```python
# In src/train.py, add:
results = model.train(
    data=args.data,
    epochs=args.epochs,
    # ... other args ...
    cls_weights=[1.0, 2.0, 3.0, 2.0]  # Adjust based on your data
)
```

**Expected Improvement:** +3-10% mAP (especially for minority classes)

---

### Strategy 7: Clean Your Data ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê

**Check for Issues:**

1. **Incorrect Labels**
   - Manually review random samples
   - Fix wrong bounding boxes
   - Fix wrong species labels

2. **Missing Annotations**
   - Some parasites not labeled
   - Reduces recall

3. **Low Quality Images**
   - Blurry images
   - Poor lighting
   - Remove or improve

**Create validation script:**

```python
# validate_dataset.py
import cv2
from pathlib import Path

def check_dataset():
    img_dir = Path("Dataset_DatasetNinja/images/train")
    lbl_dir = Path("Dataset_DatasetNinja/labels/train")
    
    issues = []
    
    for img_path in img_dir.glob("*.jpg"):
        # Check label exists
        lbl_path = lbl_dir / f"{img_path.stem}.txt"
        if not lbl_path.exists():
            issues.append(f"Missing label: {img_path.name}")
            continue
        
        # Check image quality
        img = cv2.imread(str(img_path))
        if img is None:
            issues.append(f"Corrupt image: {img_path.name}")
            continue
        
        # Check label format
        with open(lbl_path) as f:
            for line_num, line in enumerate(f, 1):
                parts = line.strip().split()
                if len(parts) != 5:
                    issues.append(f"Bad label format: {img_path.name} line {line_num}")
                try:
                    cls, x, y, w, h = map(float, parts)
                    if not (0 <= x <= 1 and 0 <= y <= 1 and 0 <= w <= 1 and 0 <= h <= 1):
                        issues.append(f"Out of range coords: {img_path.name}")
                except:
                    issues.append(f"Invalid values: {img_path.name}")
    
    return issues

if __name__ == "__main__":
    issues = check_dataset()
    print(f"Found {len(issues)} issues")
    for issue in issues[:20]:  # Show first 20
        print(f"  - {issue}")
```

**Expected Improvement:** +5-15% mAP (depends on data quality)

---

### Strategy 8: Adjust Learning Rate ‚≠ê‚≠ê‚≠ê

**Try Different Learning Rates:**

```bash
# Lower (more stable, slower)
python src/train.py \
  --data config/data_datasetninja.yaml \
  --lr0 0.005 \
  --lrf 0.01

# Higher (faster, might be unstable)
python src/train.py \
  --data config/data_datasetninja.yaml \
  --lr0 0.02 \
  --lrf 0.01
```

**Or use learning rate finder:**

```python
# Add to train.py before training
from ultralytics import YOLO

model = YOLO('yolov8n.pt')
model.tune(data='config/data_datasetninja.yaml')  # Auto-find best LR
```

**Expected Improvement:** +2-5% mAP

---

### Strategy 9: Multi-Scale Training ‚≠ê‚≠ê‚≠ê

**Train on multiple image sizes:**

Modify training to use variable input sizes:

```python
# In src/train.py
results = model.train(
    data=args.data,
    epochs=args.epochs,
    imgsz=640,
    scale=0.5,  # Scale images between 50-150% of imgsz
    # ... other args ...
)
```

**Expected Improvement:** +2-4% mAP

---

### Strategy 10: Ensemble Models ‚≠ê‚≠ê‚≠ê‚≠ê

**Train multiple models and combine predictions:**

```bash
# Train 3 different models
python src/train.py --model yolov8n.pt --name model1
python src/train.py --model yolov8s.pt --name model2
python src/train.py --model yolov8m.pt --name model3
```

**Combine predictions** (modify inference):

```python
# In src/infer.py
from ultralytics import YOLO

models = [
    YOLO('runs/model1/weights/best.pt'),
    YOLO('runs/model2/weights/best.pt'),
    YOLO('runs/model3/weights/best.pt')
]

# Average predictions
results_list = [model.predict(img) for model in models]
# Merge boxes with NMS
```

**Expected Improvement:** +3-8% mAP

---

### Strategy 11: Fine-tune Confidence Threshold ‚≠ê‚≠ê

**Find optimal threshold:**

```python
# test_thresholds.py
from ultralytics import YOLO
import numpy as np

model = YOLO('runs/plasmodium_yolov8/weights/best.pt')

thresholds = np.arange(0.1, 0.9, 0.05)
results = []

for conf in thresholds:
    result = model.val(
        data='config/data_datasetninja.yaml',
        conf=conf
    )
    results.append({
        'conf': conf,
        'map': result.box.map,
        'precision': result.box.mp,
        'recall': result.box.mr
    })
    print(f"Conf: {conf:.2f} -> mAP: {result.box.map:.3f}")

# Find best threshold
best = max(results, key=lambda x: x['map'])
print(f"\nBest threshold: {best['conf']:.2f}")
```

**Update inference:**
```python
# Use optimal threshold in predictions
model.predict(img, conf=0.35)  # Example: if 0.35 was best
```

**Expected Improvement:** +1-3% mAP

---

### Strategy 12: Transfer Learning from Related Domain ‚≠ê‚≠ê

**Use pre-trained medical imaging model:**

```bash
# Instead of COCO-pretrained yolov8n.pt
# Find medical imaging checkpoint if available
python src/train.py \
  --model path/to/medical_pretrained.pt \
  --data config/data_datasetninja.yaml
```

**Expected Improvement:** +3-7% mAP

---

## üîÑ Systematic Improvement Process

### Week 1: Data Quality
1. Clean and validate dataset
2. Balance classes
3. Add more diverse images

### Week 2: Training Optimization
1. Train with larger model (yolov8m)
2. Increase epochs to 200
3. Optimize learning rate

### Week 3: Advanced Techniques
1. Advanced augmentation
2. Multi-scale training
3. Higher resolution

### Week 4: Fine-tuning
1. Ensemble models
2. Optimize confidence threshold
3. Per-class optimization

---

## üìà Tracking Improvements

Create experiment log:

```markdown
# Experiment Log

## Baseline
- Model: yolov8n
- Epochs: 100
- mAP50-95: 0.65
- Date: 2025-01-15

## Experiment 1: Larger Model
- Model: yolov8m
- Epochs: 100
- mAP50-95: 0.73 (+0.08) ‚úÖ
- Date: 2025-01-16

## Experiment 2: More Epochs
- Model: yolov8m
- Epochs: 200
- mAP50-95: 0.78 (+0.05) ‚úÖ
- Date: 2025-01-17

...continue logging...
```

---

## üéØ Quick Wins (Do These First)

### 1. Clean Your Data (1-2 days)
- Fix obvious labeling errors
- Remove corrupted images
- **Impact:** High

### 2. Train Longer (1 day)
```bash
python src/train.py --epochs 200 --patience 100
```
- **Impact:** Medium-High

### 3. Use Larger Model (1 day)
```bash
python src/train.py --model yolov8m.pt --batch 8
```
- **Impact:** High

### 4. Increase Image Size (1 day)
```bash
python src/train.py --imgsz 800 --batch 8
```
- **Impact:** Medium

**Total time: ~5 days**  
**Expected improvement: +10-25% mAP**

---

## üîç Debugging Poor Performance

### If Precision is Low (many false positives):
- Increase confidence threshold
- Add negative samples (images without parasites)
- Clean false positives from training data

### If Recall is Low (missing detections):
- Lower confidence threshold
- Check for missing annotations
- Use larger model
- Increase image resolution

### If One Class Performs Poorly:
- Collect more data for that class
- Check label accuracy for that class
- Use class weights
- Data augmentation for that class

---

## üí° Advanced Tips

### 1. Use Test-Time Augmentation (TTA)
```python
model.predict(img, augment=True)  # Slower but more accurate
```

### 2. Post-Processing
```python
# Filter out very small boxes (likely noise)
min_box_area = 50  # pixels

# Filter out low-confidence detections from crowded areas
# Custom logic in inference code
```

### 3. Active Learning
1. Run model on unlabeled data
2. Manually label cases where model is uncertain
3. Add to training set
4. Retrain

### 4. Cross-Validation
Train on 5 different splits, average results:
```bash
python src/train.py --data config/fold1.yaml
python src/train.py --data config/fold2.yaml
# ... etc
```

---

## üìä Expected Results Timeline

| Strategy | Time | Improvement | Difficulty |
|----------|------|-------------|------------|
| Clean data | 2 days | +5-15% | Easy |
| Larger model | 1 day | +5-12% | Easy |
| More epochs | 1 day | +2-8% | Easy |
| More data | Variable | +5-15% | Hard |
| Augmentation | 2 days | +3-8% | Medium |
| Higher resolution | 1 day | +2-6% | Easy |
| Ensemble | 3 days | +3-8% | Medium |

---

## ‚úÖ Improvement Checklist

- [ ] Evaluated current performance
- [ ] Cleaned dataset (fixed labels)
- [ ] Balanced classes
- [ ] Trained with yolov8m or larger
- [ ] Increased epochs to 200+
- [ ] Tried higher resolution (800+)
- [ ] Added data augmentation
- [ ] Optimized confidence threshold
- [ ] Validated on separate test set
- [ ] Documented improvements

---

## üéØ Realistic Goals

**Starting from mAP50-95 = 0.65:**

- **After 1 week:** 0.70-0.75 (Quick wins)
- **After 1 month:** 0.75-0.85 (Systematic improvements)
- **After 3 months:** 0.85-0.92 (With more data + optimization)

**Diminishing returns:** Getting from 0.85 to 0.90 is MUCH harder than 0.65 to 0.70!

---

## üöÄ Next Steps

1. **Evaluate current model** - Know your baseline
2. **Pick 3 strategies** - Start with Quick Wins
3. **Test one at a time** - Measure impact
4. **Keep best changes** - Build on success
5. **Document everything** - Learn what works

**Remember:** Model improvement is iterative. Small, measured steps beat random experimentation!

Good luck! üéØ

